{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0ae29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cola0\\anaconda3\\envs\\nlp-project\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader module imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os \n",
    "import torch\n",
    "from transformers import BertTokenizerFast \n",
    "\n",
    "project_root = os.path.abspath(\"..\")  # se il notebook √® in /report\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data.loader import DataLoader\n",
    "\n",
    "print(\"DataLoader module imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176db2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer e DataLoader inizializzati. Cerca i primi 50 articoli.\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 64\n",
    "BATCH_SIZE = 4\n",
    "NUM_SAMPLES = 50  \n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "loader = DataLoader(\n",
    "    tokenizer, \n",
    "    max_length=MAX_LENGTH, \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Tokenizer e DataLoader inizializzati. Cerca i primi {NUM_SAMPLES} articoli.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c0e25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Test Data Loading pipeline...\n",
      " Loading Wikipedia (train) in streaming mode...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cola0\\anaconda3\\envs\\nlp-project\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\cola0\\.cache\\huggingface\\hub\\datasets--wikitext. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the dataset...\n",
      "Tokenizing the dataset...\n",
      "‚è≥ Fetching first batch...\n",
      "\n",
      "‚úÖ Batch caricato con successo!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Test Data Loading pipeline...\")\n",
    "\n",
    "# 3. Ottieni DataLoader\n",
    "try:\n",
    "    train_loader = loader.get_dataloader(split=\"train\", num_samples=NUM_SAMPLES)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Errore nella creazione del DataLoader: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"‚è≥ Fetching first batch...\")\n",
    "\n",
    "# Proviamo a prendere il primo batch\n",
    "try:\n",
    "    first_batch = next(iter(train_loader))\n",
    "    print(\"\\n‚úÖ Batch caricato con successo!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Errore nel caricamento dati: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e16f2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Risultati del Batch ---\n",
      "   Keys: KeysView({'input_ids': tensor([[  101, 12411,  5558,  2053, 11748,  4801,  4360,  1017,  1024,  1026,\n",
      "          4895,  2243,   103, 11906,  1006,  2887,  1024,   103,  1806,  1671,\n",
      "         30222, 30218, 30259, 30227, 30255, 30258, 30219,   103,  1010,  5507,\n",
      "           103, 11748,  4801,  4360,   103,  1996, 11686,  1017,  1007,  1010,\n",
      "          4141,  3615,  2000,  2004, 11748,  4801,  4360, 11906,  3523,  2648,\n",
      "          2900,  1010,  2003,  1037,  8608,  2535,   103,  1011,  1030,   103,\n",
      "          2678,   103,  2764,   102],\n",
      "        [  101,  1996,  2208,  2211,  2458,  1999,  2230,  1010,  4755,  2058,\n",
      "          1037,  2312,   103,  1997,  1996,  2147,  2589,  2006, 11748,  4801,\n",
      "          4360, 11906,  2462,  1012,  2096,  2009,  6025,  1996,  3115,  2838,\n",
      "          1997,  1996,  2186, 10022,  2009,  2036,  9601,  3674, 24081,  1010,\n",
      "          2107,   103,  2437,  1996,  2208,   103,  1026,  4895,  2243,  1028,\n",
      "          2005,  2186, 24159,   103,  2839,  5859,  1026,  4895,  2243,  1028,\n",
      "         10189, 23099,  1998,   102],\n",
      "        [  101,  2004,  2007,  3025,  1026,  4895,  2243,   103, 11906,   103,\n",
      "          1010, 11748,  4801,  4360, 11906,  3523,  2003,  1037,  8608,  2535,\n",
      "          1030,  1011,  1030,  2652,  2208,  2073,  2867,  2202,  2491,  1997,\n",
      "          1037,  2510,   103,   103,  2202,  2112,  1999,  6416,  2114,  4099,\n",
      "          2749,  1012,  3441,  2024,   103,  2083,  5021,  2338,  1030,   103,\n",
      "          1030,  2066,  9320,   103,  6579,  2839,  9668,  1010,  2007,  3494,\n",
      "          4092,  6822,   103,   102],\n",
      "        [  101,   103,  2024,  4055,  2046,  2274,  4280,  1024, 10158,  1010,\n",
      "          1026,  4895,  2243,  1028,  1010,   103,  1010,  1026,  4895,  2243,\n",
      "          1028,  1998, 10612,  5268,  1012,  1026,  4895,  2243,   103,  2064,\n",
      "          6942,  4280,  2011,  5278,   103,  4137,  5195,  1012,  5278,  2465,\n",
      "          2515,  2025,  6551,  7461,  1996, 26319,   103,  2096,  1999,  1037,\n",
      "          3025,  2465,  1012,  2007,  3377,  1999,  2645,  1010,  3325,  2685,\n",
      "          2024,  3018,  2000,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         1028, -100, -100, -100, -100, 1856, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, 2509, -100, -100, 1012, -100, -100, -100, 1997, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, 1030, -100, -100, 2652,\n",
      "         -100, 2208, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         4664, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, 3115, -100, -100, -100, -100, 1010, -100, -100,\n",
      "         -100, -100, -100, -100, -100, 2004, -100, -100, -100, 2062, -100, -100,\n",
      "         -100, -100, -100, -100, -100, 1012, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100],\n",
      "        [-100, -100, -100, -100, -100, -100, -100, 1028, -100, 2399, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, 3131, 1998, -100, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, 2024, 2409, -100, -100, -100,\n",
      "         -100, 1011, -100, -100, -100, 2007, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, 2083, -100],\n",
      "        [-100, 3629, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, 6145, -100, -100, -100, -100, 1028, -100, -100, -100,\n",
      "         -100, -100, -100, -100, 1028, -100, -100, -100, -100, -100, 2037, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4227, -100,\n",
      "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         -100, -100, -100, -100]])})\n",
      "   Input IDs Shape: torch.Size([4, 64]) (Atteso: torch.Size([4, 64]))\n",
      "   Labels Shape: torch.Size([4, 64]) (Atteso: torch.Size([4, 64]))\n",
      "   Totale token mascherati nel batch: 29\n",
      "\n",
      "--- Visualizzazione Labels del primo esempio (solo i primi 10 token) ---\n",
      "   Labels: [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "\n",
      "‚úÖ Test dei dati superato: le dimensioni sono corrette e il mascheramento MLM √® attivo.\n"
     ]
    }
   ],
   "source": [
    "# Verifica delle Shape\n",
    "expected_shape = torch.Size([BATCH_SIZE, MAX_LENGTH])\n",
    "\n",
    "print(\"--- Risultati del Batch ---\")\n",
    "print(f\"   Keys: {first_batch.keys()}\")\n",
    "print(f\"   Input IDs Shape: {first_batch['input_ids'].shape} (Atteso: {expected_shape})\") \n",
    "print(f\"   Labels Shape: {first_batch['labels'].shape} (Atteso: {expected_shape})\")       \n",
    "\n",
    "# Analisi delle Labels\n",
    "# -100 indica i token NON mascherati/NON da predire (standard MLM)\n",
    "# Qualsiasi valore >= 0 indica il token originale (quello da predire)\n",
    "masked_count = (first_batch['labels'] != -100).sum().item()\n",
    "print(f\"   Totale token mascherati nel batch: {masked_count}\")\n",
    "\n",
    "print(\"\\n--- Visualizzazione Labels del primo esempio (solo i primi 10 token) ---\")\n",
    "print(f\"   Labels: {first_batch['labels'][0][:10].tolist()}\")\n",
    "\n",
    "if first_batch['input_ids'].shape == expected_shape and masked_count > 0:\n",
    "    print(\"\\n‚úÖ Test dei dati superato: le dimensioni sono corrette e il mascheramento MLM √® attivo.\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Test fallito.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
